{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijitgayen/SNA_As_Msc_projects/blob/main/10_Word2Vec_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAhGKTeX_eNq"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsuk-heo/tf2/blob/master/jupyter_notebooks/10.Word2Vec_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJcGdmRg_eN6"
      },
      "source": [
        "# Sentence Classification using LSTM and Pretrained Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F61kUpXW_eN8"
      },
      "source": [
        "We will train and test sentence classification using LSTM, and Pretrained Word2Vec.  \n",
        "You can find visualization of our code below."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add libary"
      ],
      "metadata": {
        "id": "AbaDII3m_uMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGewIn95_eOT"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSk_2_1n_eOV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wzwv4cM_eOX"
      },
      "outputs": [],
      "source": [
        "# Load Pretrained Word2Vec\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHI0i3i0_eOY"
      },
      "outputs": [],
      "source": [
        "def get_max_length(df):\n",
        "    \"\"\"\n",
        "    get max token counts from train data, \n",
        "    so we use this number as fixed length input to RNN cell\n",
        "    \"\"\"\n",
        "    max_length = 0\n",
        "    for row in df['sentiment']:\n",
        "        if len(row.split(\" \")) > max_length:\n",
        "            max_length = len(row.split(\" \"))\n",
        "    return max_length\n",
        "\n",
        "def get_word2vec_enc(reviews):\n",
        "    \"\"\"\n",
        "    get word2vec value for each word in sentence.\n",
        "    concatenate word in numpy array, so we can use it as RNN input\n",
        "    \"\"\"\n",
        "    encoded_reviews = []\n",
        "    for review in reviews:\n",
        "        tokens = review.split(\" \")\n",
        "        word2vec_embedding = embed(tokens)\n",
        "        encoded_reviews.append(word2vec_embedding)\n",
        "    return encoded_reviews\n",
        "        \n",
        "def get_padded_encoded_reviews(encoded_reviews):\n",
        "    \"\"\"\n",
        "    for short sentences, we prepend zero padding so all input to RNN has same length\n",
        "    \"\"\"\n",
        "    padded_reviews_encoding = []\n",
        "    for enc_review in encoded_reviews:\n",
        "        zero_padding_cnt = max_length - enc_review.shape[0]\n",
        "        pad = np.zeros((1, 250))\n",
        "        for i in range(zero_padding_cnt):\n",
        "            enc_review = np.concatenate((pad, enc_review), axis=0)\n",
        "        padded_reviews_encoding.append(enc_review)\n",
        "    return padded_reviews_encoding\n",
        "\n",
        "def sentiment_encode(sentiment):\n",
        "    \"\"\"\n",
        "    return one hot encoding for Y value\n",
        "    \"\"\"\n",
        "    if sentiment == 0:\n",
        "        return [1,0]\n",
        "    if sentiment == 2:\n",
        "        return [0.5,0.5]\n",
        "    else:\n",
        "        return [0,1]\n",
        "    \n",
        "def preprocess(df):\n",
        "    \"\"\"\n",
        "    encode text value to numeric value\n",
        "    \"\"\"\n",
        "    # encode words into word2vec\n",
        "    reviews = df['sentiment'].tolist()\n",
        "    \n",
        "    encoded_reviews = get_word2vec_enc(reviews)\n",
        "    padded_encoded_reviews = get_padded_encoded_reviews(encoded_reviews)\n",
        "    # encoded sentiment\n",
        "    sentiments = df['lebal'].tolist()\n",
        "    encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]\n",
        "    X = np.array(padded_encoded_reviews)\n",
        "    Y = np.array(encoded_sentiment)\n",
        "    return X, Y "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8-YLayo_eOb"
      },
      "source": [
        "# Preprocess (encode text to number)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOhHRh-D92vv",
        "outputId": "7d4c30a7-1518-44f8-df63-af0966e8825d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDatas=pd.read_csv('drive/MyDrive/data_set/sts-test_data_set/training.csv', names=['lebal','id','date','Query','About','sentiment'],encoding='latin-1'); #skiping these two rows as they have some bad data\n",
        "testData=pd.read_csv('drive/MyDrive/data_set/sts-test_data_set/testdata.csv', names=['lebal','id','date','Query','About','sentiment'],encoding='latin-1'); #test_data\n",
        "print(tweetsDatas.head())\n",
        "print(tweetsDatas.lebal.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFgFx5fUByuu",
        "outputId": "1b6b747e-0c75-4487-8c11-be22da84c722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   lebal          id                          date     Query            About  \\\n",
            "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
            "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
            "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
            "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
            "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
            "\n",
            "                                           sentiment  \n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
            "1  is upset that he can't update his Facebook by ...  \n",
            "2  @Kenichan I dived many times for the ball. Man...  \n",
            "3    my whole body feels itchy and like its on fire   \n",
            "4  @nationwideclass no, it's not behaving at all....  \n",
            "0    800000\n",
            "4    800000\n",
            "Name: lebal, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsData=tweetsDatas.sample(n=1000000,replace=True)\n",
        "tweetsData_train=tweetsData[0:10000]\n",
        "tweetsData_train.lebal.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt1oajecDk5-",
        "outputId": "0c3ad52c-74bd-4d3d-9b71-3a76f27f1f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5056\n",
              "4    4944\n",
              "Name: lebal, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a6PI6pD_eOc"
      },
      "outputs": [],
      "source": [
        "df=tweetsData_train\n",
        "# max_length is used for max sequence of input\n",
        "max_length = get_max_length(df)\n",
        "\n",
        "train_X, train_Y = preprocess(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0REz_zM_eOd"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhNRBzA1_eOf"
      },
      "outputs": [],
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efpd3TF__eOh"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRO932fcAVdF",
        "outputId": "94abf8b2-ebd2-416b-f37b-ac71049a11aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       ...,\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He_9VTLk_eOi",
        "outputId": "a1d71355-907b-4f86-e395-0f061a016698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 8s 19ms/step - loss: 0.6551 - accuracy: 0.6088\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6093 - accuracy: 0.6724\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5891 - accuracy: 0.6851\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5759 - accuracy: 0.7051\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.5683 - accuracy: 0.7050\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5634 - accuracy: 0.7086\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5559 - accuracy: 0.7118\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.5466 - accuracy: 0.7173\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5447 - accuracy: 0.7208\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5347 - accuracy: 0.7257\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5299 - accuracy: 0.7303\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5209 - accuracy: 0.7375\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5133 - accuracy: 0.7467\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5051 - accuracy: 0.7480\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4957 - accuracy: 0.7583\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4912 - accuracy: 0.7565\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4781 - accuracy: 0.7702\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4689 - accuracy: 0.7743\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4634 - accuracy: 0.7794\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4563 - accuracy: 0.7818\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4442 - accuracy: 0.7894\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4347 - accuracy: 0.7919\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 6s 21ms/step - loss: 0.4318 - accuracy: 0.7991\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4207 - accuracy: 0.8055\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4103 - accuracy: 0.8089\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.4003 - accuracy: 0.8154\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3931 - accuracy: 0.8157\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3852 - accuracy: 0.8209\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3745 - accuracy: 0.8270\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3685 - accuracy: 0.8327\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3557 - accuracy: 0.8406\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3473 - accuracy: 0.8453\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3398 - accuracy: 0.8442\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3281 - accuracy: 0.8539\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3263 - accuracy: 0.8560\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3176 - accuracy: 0.8615\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3062 - accuracy: 0.8653\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3027 - accuracy: 0.8697\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2934 - accuracy: 0.8714\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.2885 - accuracy: 0.8779\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.2767 - accuracy: 0.8805\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2650 - accuracy: 0.8862\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2734 - accuracy: 0.8836\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2587 - accuracy: 0.8893\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2489 - accuracy: 0.8977\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.2355 - accuracy: 0.9021\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.2389 - accuracy: 0.9013\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.2241 - accuracy: 0.9096\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2258 - accuracy: 0.9058\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.2225 - accuracy: 0.9078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff454d7e110>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print('Train...')\n",
        "model.fit(train_X, train_Y,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJpAQrF2_eOj",
        "outputId": "87bb6e4d-583f-4ebf-c61b-a0a6168adf27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 32)                36224     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,290\n",
            "Trainable params: 36,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf_Vaei__eOk"
      },
      "source": [
        "# Test\n",
        "your model can predict correctly even for unseen words from training.  \n",
        "This is the most benefit of using pretrained word embedding.  \n",
        "Why? pretrained embedding will encode [better], [nice] to similar vector of [best]  \n",
        "even if these words were not in train.  \n",
        "therefore, the input vector to RNN is similar, so correct answers for even these unseen words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_iOjy4G_eOl",
        "outputId": "cf55c923-ecb8-4a17-e15a-b7bd72219365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    54\n",
            "4    45\n",
            "Name: lebal, dtype: int64\n",
            "4/4 - 0s - loss: 1.2463 - accuracy: 0.6869 - 42ms/epoch - 10ms/step\n",
            "Test score: 1.246348261833191\n",
            "Test accuracy: 0.6868686676025391\n"
          ]
        }
      ],
      "source": [
        "test_df=tweetsData[100001:100100]\n",
        "print(test_df.lebal.value_counts())\n",
        "\n",
        "test_X, test_Y = preprocess(test_df)\n",
        "\n",
        "score, acc = model.evaluate(test_X, test_Y, verbose=2)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2dzRhVYGGxpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=testData\n",
        "print(test_df.lebal.value_counts())\n",
        "\n",
        "test_X, test_Y = preprocess(test_df)\n",
        "\n",
        "score, acc = model.evaluate(test_X, test_Y, verbose=2)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "id": "lwxxgYLUG3OU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "10.Word2Vec_LSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}