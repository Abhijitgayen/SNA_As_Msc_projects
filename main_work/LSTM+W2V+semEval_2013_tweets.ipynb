{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM+W2V+semEval-2013-tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXWY4oLj4zRRQXFcLVCux0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijitgayen/SNA_As_Msc_projects/blob/main/main_work/LSTM%2BW2V%2BsemEval_2013_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Libary_enter"
      ],
      "metadata": {
        "id": "-y0vigCPueLA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rebbDJ30uaMu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained Word2Vec\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
      ],
      "metadata": {
        "id": "bmIwS37husY-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some_function for prepossing"
      ],
      "metadata": {
        "id": "XXq91ml2u3Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length(df):\n",
        "    \"\"\"\n",
        "    get max token counts from train data, \n",
        "    so we use this number as fixed length input to RNN cell\n",
        "    \"\"\"\n",
        "    max_length = 0\n",
        "    for row in df['tweet']:\n",
        "        if len(row.split(\" \")) > max_length:\n",
        "            max_length = len(row.split(\" \"))\n",
        "    return max_length\n",
        "\n",
        "def get_word2vec_enc(reviews):\n",
        "    \"\"\"\n",
        "    get word2vec value for each word in sentence.\n",
        "    concatenate word in numpy array, so we can use it as RNN input\n",
        "    \"\"\"\n",
        "    encoded_reviews = []\n",
        "    for review in reviews:\n",
        "        tokens = review.split(\" \")\n",
        "        word2vec_embedding = embed(tokens)\n",
        "        encoded_reviews.append(word2vec_embedding)\n",
        "    return encoded_reviews\n",
        "        \n",
        "def get_padded_encoded_reviews(encoded_reviews):\n",
        "    \"\"\"\n",
        "    for short sentences, we prepend zero padding so all input to RNN has same length\n",
        "    \"\"\"\n",
        "    padded_reviews_encoding = []\n",
        "    for enc_review in encoded_reviews:\n",
        "        zero_padding_cnt = max_length - enc_review.shape[0]\n",
        "        pad = np.zeros((1, 250))\n",
        "        for i in range(zero_padding_cnt):\n",
        "            enc_review = np.concatenate((pad, enc_review), axis=0)\n",
        "        padded_reviews_encoding.append(enc_review)\n",
        "    return padded_reviews_encoding\n",
        "\n",
        "def sentiment_encode(sentiment):\n",
        "    \"\"\"\n",
        "    return one hot encoding for Y value\n",
        "    \"\"\"\n",
        "    if sentiment == 'positive':\n",
        "        return [1,0]\n",
        "    if sentiment == 'neutral':\n",
        "        return [0.5,0.5]\n",
        "    else:\n",
        "        return [0,1]\n",
        "    \n",
        "def preprocess(df):\n",
        "    \"\"\"\n",
        "    encode text value to numeric value\n",
        "    \"\"\"\n",
        "    # encode words into word2vec\n",
        "    reviews = df['tweet'].tolist()\n",
        "    \n",
        "    encoded_reviews = get_word2vec_enc(reviews)\n",
        "    padded_encoded_reviews = get_padded_encoded_reviews(encoded_reviews)\n",
        "    # encoded sentiment\n",
        "    sentiments = df['label'].tolist()\n",
        "    encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]\n",
        "    X = np.array(padded_encoded_reviews)\n",
        "    Y = np.array(encoded_sentiment)\n",
        "    return X, Y "
      ],
      "metadata": {
        "id": "c3hq3ITYu3f7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data_Set_add"
      ],
      "metadata": {
        "id": "m2FFiMpFu_sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzWBbb2MvAGE",
        "outputId": "ec286f51-bfa2-4021-f112-e7d195c908ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDatas=pd.read_csv('/content/drive/MyDrive/2017_data_set/dataset/train/twitter-2013train-A.txt', sep=\"\\t\", header=None, names=[\"id\",\"label\", \"tweet\"]); #skiping these two rows as they have some bad data\n",
        "testData=pd.read_csv('/content/drive/MyDrive/2017_data_set/dataset/train/twitter-2013test-A.txt',sep=\"\\t\", header=None, names=[\"id\",\"label\", \"tweet\"]); #test_data"
      ],
      "metadata": {
        "id": "WYt4dEcuvIr9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweetsDatas.head())\n",
        "print(tweetsDatas.label.value_counts())\n",
        "print(testData.head())\n",
        "print(testData.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3SX5i0HvKlC",
        "outputId": "efe44ca0-ce2b-4b22-b251-4c57f166d782"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   id     label  \\\n",
            "0  264183816548130816  positive   \n",
            "1  263405084770172928  negative   \n",
            "2  262163168678248449  negative   \n",
            "3  264249301910310912  negative   \n",
            "4  262682041215234048   neutral   \n",
            "\n",
            "                                               tweet  \n",
            "0  Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
            "1  Theo Walcott is still shit\\u002c watch Rafa an...  \n",
            "2  its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
            "3  Iranian general says Israel\\u2019s Iron Dome c...  \n",
            "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...  \n",
            "neutral     4586\n",
            "positive    3640\n",
            "negative    1458\n",
            "Name: label, dtype: int64\n",
            "                   id     label  \\\n",
            "0  264238274963451904  positive   \n",
            "1  218775148495515649  positive   \n",
            "2  258965201766998017   neutral   \n",
            "3  262926411352903682  negative   \n",
            "4  171874368908050432   neutral   \n",
            "\n",
            "                                               tweet  \n",
            "0  @jjuueellzz down in the Atlantic city, ventnor...  \n",
            "1  Musical awareness: Great Big Beautiful Tomorro...  \n",
            "2  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...  \n",
            "3  Kapan sih lo ngebuktiin,jan ngomong doang Susa...  \n",
            "4  Excuse the connectivity of this live stream, f...  \n",
            "neutral     1513\n",
            "positive    1475\n",
            "negative     559\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=tweetsDatas\n",
        "# max_length is used for max sequence of input\n",
        "max_length = get_max_length(df)\n",
        "print(max_length)\n",
        "\n",
        "train_X, train_Y = preprocess(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maz3Wd7pvY85",
        "outputId": "bc38e921-dc0a-48a6-d1fd-1016919953d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALL_models"
      ],
      "metadata": {
        "id": "h4UnyOYKvjdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ByW-tyGuvhUo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ugV0lpT2wJud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train Models"
      ],
      "metadata": {
        "id": "5DXCJAYvv3if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train...')\n",
        "model.fit(train_X, train_Y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGFxF_HNvofQ",
        "outputId": "e0d99db8-14a7-423b-e4c0-5cd9d639b154"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/100\n",
            "303/303 [==============================] - 20s 62ms/step - loss: 0.6720 - accuracy: 0.7874\n",
            "Epoch 2/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.6314 - accuracy: 0.7988\n",
            "Epoch 3/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.6163 - accuracy: 0.7951\n",
            "Epoch 4/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.6083 - accuracy: 0.7928\n",
            "Epoch 5/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.5998 - accuracy: 0.7980\n",
            "Epoch 6/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.5920 - accuracy: 0.7965\n",
            "Epoch 7/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.5859 - accuracy: 0.7887\n",
            "Epoch 8/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.5773 - accuracy: 0.7981\n",
            "Epoch 9/100\n",
            "303/303 [==============================] - 18s 61ms/step - loss: 0.5702 - accuracy: 0.7954\n",
            "Epoch 10/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.5598 - accuracy: 0.7919\n",
            "Epoch 11/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.5475 - accuracy: 0.7974\n",
            "Epoch 12/100\n",
            "303/303 [==============================] - 18s 61ms/step - loss: 0.5356 - accuracy: 0.7918\n",
            "Epoch 13/100\n",
            "303/303 [==============================] - 18s 61ms/step - loss: 0.5242 - accuracy: 0.7957\n",
            "Epoch 14/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.5095 - accuracy: 0.7969\n",
            "Epoch 15/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.4964 - accuracy: 0.8017\n",
            "Epoch 16/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4858 - accuracy: 0.8042\n",
            "Epoch 17/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4674 - accuracy: 0.8042\n",
            "Epoch 18/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4531 - accuracy: 0.8013\n",
            "Epoch 19/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.4465 - accuracy: 0.7979\n",
            "Epoch 20/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4355 - accuracy: 0.8007\n",
            "Epoch 21/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4250 - accuracy: 0.7987\n",
            "Epoch 22/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4180 - accuracy: 0.7970\n",
            "Epoch 23/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.4090 - accuracy: 0.7929\n",
            "Epoch 24/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3994 - accuracy: 0.7898\n",
            "Epoch 25/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3962 - accuracy: 0.7897\n",
            "Epoch 26/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3915 - accuracy: 0.7848\n",
            "Epoch 27/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3843 - accuracy: 0.7799\n",
            "Epoch 28/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3844 - accuracy: 0.7820\n",
            "Epoch 29/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3788 - accuracy: 0.7792\n",
            "Epoch 30/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3730 - accuracy: 0.7731\n",
            "Epoch 31/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3711 - accuracy: 0.7723\n",
            "Epoch 32/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3656 - accuracy: 0.7748\n",
            "Epoch 33/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3668 - accuracy: 0.7712\n",
            "Epoch 34/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3728 - accuracy: 0.7784\n",
            "Epoch 35/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3624 - accuracy: 0.7719\n",
            "Epoch 36/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3597 - accuracy: 0.7641\n",
            "Epoch 37/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3568 - accuracy: 0.7693\n",
            "Epoch 38/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3560 - accuracy: 0.7649\n",
            "Epoch 39/100\n",
            "303/303 [==============================] - 19s 64ms/step - loss: 0.3541 - accuracy: 0.7627\n",
            "Epoch 40/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3550 - accuracy: 0.7678\n",
            "Epoch 41/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3561 - accuracy: 0.7681\n",
            "Epoch 42/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3528 - accuracy: 0.7625\n",
            "Epoch 43/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3510 - accuracy: 0.7685\n",
            "Epoch 44/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3547 - accuracy: 0.7683\n",
            "Epoch 45/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3517 - accuracy: 0.7682\n",
            "Epoch 46/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3492 - accuracy: 0.7616\n",
            "Epoch 47/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3499 - accuracy: 0.7638\n",
            "Epoch 48/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3474 - accuracy: 0.7670\n",
            "Epoch 49/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3474 - accuracy: 0.7628\n",
            "Epoch 50/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3473 - accuracy: 0.7672\n",
            "Epoch 51/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3702 - accuracy: 0.7687\n",
            "Epoch 52/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3534 - accuracy: 0.7700\n",
            "Epoch 53/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3438 - accuracy: 0.7595\n",
            "Epoch 54/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3446 - accuracy: 0.7627\n",
            "Epoch 55/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3427 - accuracy: 0.7592\n",
            "Epoch 56/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3404 - accuracy: 0.7654\n",
            "Epoch 57/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3414 - accuracy: 0.7607\n",
            "Epoch 58/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3411 - accuracy: 0.7599\n",
            "Epoch 59/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3421 - accuracy: 0.7659\n",
            "Epoch 60/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3546 - accuracy: 0.7699\n",
            "Epoch 61/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3452 - accuracy: 0.7681\n",
            "Epoch 62/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3404 - accuracy: 0.7677\n",
            "Epoch 63/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3461 - accuracy: 0.7632\n",
            "Epoch 64/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3443 - accuracy: 0.7662\n",
            "Epoch 65/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3403 - accuracy: 0.7621\n",
            "Epoch 66/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3382 - accuracy: 0.7622\n",
            "Epoch 67/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3372 - accuracy: 0.7623\n",
            "Epoch 68/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3370 - accuracy: 0.7616\n",
            "Epoch 69/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3658 - accuracy: 0.7648\n",
            "Epoch 70/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3474 - accuracy: 0.7630\n",
            "Epoch 71/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3427 - accuracy: 0.7700\n",
            "Epoch 72/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3359 - accuracy: 0.7636\n",
            "Epoch 73/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3343 - accuracy: 0.7650\n",
            "Epoch 74/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3342 - accuracy: 0.7570\n",
            "Epoch 75/100\n",
            "303/303 [==============================] - 19s 61ms/step - loss: 0.3358 - accuracy: 0.7645\n",
            "Epoch 76/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3366 - accuracy: 0.7661\n",
            "Epoch 77/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3501 - accuracy: 0.7627\n",
            "Epoch 78/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3613 - accuracy: 0.7729\n",
            "Epoch 79/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3449 - accuracy: 0.7701\n",
            "Epoch 80/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3366 - accuracy: 0.7649\n",
            "Epoch 81/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3339 - accuracy: 0.7656\n",
            "Epoch 82/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3331 - accuracy: 0.7660\n",
            "Epoch 83/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3335 - accuracy: 0.7666\n",
            "Epoch 84/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3340 - accuracy: 0.7662\n",
            "Epoch 85/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3348 - accuracy: 0.7633\n",
            "Epoch 86/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3362 - accuracy: 0.7646\n",
            "Epoch 87/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3369 - accuracy: 0.7662\n",
            "Epoch 88/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3371 - accuracy: 0.7633\n",
            "Epoch 89/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3395 - accuracy: 0.7605\n",
            "Epoch 90/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3473 - accuracy: 0.7675\n",
            "Epoch 91/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3464 - accuracy: 0.7705\n",
            "Epoch 92/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3538 - accuracy: 0.7682\n",
            "Epoch 93/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3493 - accuracy: 0.7714\n",
            "Epoch 94/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3369 - accuracy: 0.7676\n",
            "Epoch 95/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3331 - accuracy: 0.7625\n",
            "Epoch 96/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3320 - accuracy: 0.7648\n",
            "Epoch 97/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3316 - accuracy: 0.7690\n",
            "Epoch 98/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3317 - accuracy: 0.7682\n",
            "Epoch 99/100\n",
            "303/303 [==============================] - 19s 62ms/step - loss: 0.3327 - accuracy: 0.7583\n",
            "Epoch 100/100\n",
            "303/303 [==============================] - 19s 63ms/step - loss: 0.3331 - accuracy: 0.7639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92f114ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=testData\n",
        "print(test_df.label.value_counts())\n",
        "max_length = get_max_length(test_df)\n",
        "test_X, test_Y = preprocess(test_df)\n",
        "\n",
        "score, acc = model.evaluate(test_X, test_Y, verbose=2)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lb9dxHcvo0G",
        "outputId": "3f7d76e8-33a1-41bf-b9bb-b89bd2883460"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral     1513\n",
            "positive    1475\n",
            "negative     559\n",
            "Name: label, dtype: int64\n",
            "111/111 - 4s - loss: 0.9994 - accuracy: 0.6778 - 4s/epoch - 35ms/step\n",
            "Test score: 0.9994271397590637\n",
            "Test accuracy: 0.6777558326721191\n"
          ]
        }
      ]
    }
  ]
}