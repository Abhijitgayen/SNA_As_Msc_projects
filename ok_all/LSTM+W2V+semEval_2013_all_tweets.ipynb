{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM+W2V+semEval-2013_all-tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLTwHCvBp857GpOSZo0gtM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijitgayen/SNA_As_Msc_projects/blob/main/ok_all/LSTM%2BW2V%2BsemEval_2013_all_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Libary_enter"
      ],
      "metadata": {
        "id": "-y0vigCPueLA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rebbDJ30uaMu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained Word2Vec\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
      ],
      "metadata": {
        "id": "bmIwS37husY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some_function for prepossing"
      ],
      "metadata": {
        "id": "XXq91ml2u3Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length(df):\n",
        "    \"\"\"\n",
        "    get max token counts from train data, \n",
        "    so we use this number as fixed length input to RNN cell\n",
        "    \"\"\"\n",
        "    max_length = 0\n",
        "    for row in df['tweet']:\n",
        "        if len(row.split(\" \")) > max_length:\n",
        "            max_length = len(row.split(\" \"))\n",
        "    return max_length\n",
        "\n",
        "def get_word2vec_enc(reviews):\n",
        "    \"\"\"\n",
        "    get word2vec value for each word in sentence.\n",
        "    concatenate word in numpy array, so we can use it as RNN input\n",
        "    \"\"\"\n",
        "    encoded_reviews = []\n",
        "    for review in reviews:\n",
        "        tokens = review.split(\" \")\n",
        "        word2vec_embedding = embed(tokens)\n",
        "        encoded_reviews.append(word2vec_embedding)\n",
        "    return encoded_reviews\n",
        "        \n",
        "def get_padded_encoded_reviews(encoded_reviews):\n",
        "    \"\"\"\n",
        "    for short sentences, we prepend zero padding so all input to RNN has same length\n",
        "    \"\"\"\n",
        "    padded_reviews_encoding = []\n",
        "    for enc_review in encoded_reviews:\n",
        "        zero_padding_cnt = max_length - enc_review.shape[0]\n",
        "        pad = np.zeros((1, 250))\n",
        "        for i in range(zero_padding_cnt):\n",
        "            enc_review = np.concatenate((pad, enc_review), axis=0)\n",
        "        padded_reviews_encoding.append(enc_review)\n",
        "    return padded_reviews_encoding\n",
        "\n",
        "def sentiment_encode(sentiment):\n",
        "    \"\"\"\n",
        "    return one hot encoding for Y value\n",
        "    \"\"\"\n",
        "    if sentiment == 'positive':\n",
        "        return [1,0]\n",
        "    if sentiment == 'neutral':\n",
        "        return [0.5,0.5]\n",
        "    else:\n",
        "        return [0,1]\n",
        "    \n",
        "def preprocess(df):\n",
        "    \"\"\"\n",
        "    encode text value to numeric value\n",
        "    \"\"\"\n",
        "    # encode words into word2vec\n",
        "    reviews = df['tweet'].tolist()\n",
        "    \n",
        "    encoded_reviews = get_word2vec_enc(reviews)\n",
        "    padded_encoded_reviews = get_padded_encoded_reviews(encoded_reviews)\n",
        "    # encoded sentiment\n",
        "    sentiments = df['label'].tolist()\n",
        "    encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]\n",
        "    X = np.array(padded_encoded_reviews)\n",
        "    Y = np.array(encoded_sentiment)\n",
        "    return X, Y "
      ],
      "metadata": {
        "id": "c3hq3ITYu3f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data_Set_add"
      ],
      "metadata": {
        "id": "m2FFiMpFu_sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzWBbb2MvAGE",
        "outputId": "0ab3db51-a390-4ae2-afe6-0d8bb1c1e104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_2013_At=pd.read_csv('/content/drive/MyDrive/2017_data_set/main_data/GOLD/Subtask_A/twitter-2013train-A.txt', sep=\"\\t\", header=None, names=[\"id\",\"label\", \"tweet\"]);\n",
        "tweets_2013_Ad=pd.read_csv('/content/drive/MyDrive/2017_data_set/main_data/GOLD/Subtask_A/twitter-2013dev-A.txt', sep=\"\\t\", header=None, names=[\"id\",\"label\", \"tweet\"]);\n",
        "tweets_2013_A=pd.read_csv('/content/drive/MyDrive/2017_data_set/main_data/GOLD/Subtask_A/twitter-2013test-A.txt', sep=\"\\t\", header=None, names=[\"id\",\"label\", \"tweet\"]); \n",
        "tweetsDatas=pd.concat([tweets_2013_At,tweets_2013_Ad]);\n",
        "testData=tweets_2013_A"
      ],
      "metadata": {
        "id": "_hyDYaTm_GYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweetsDatas.head())\n",
        "print(tweetsDatas.label.value_counts())\n",
        "print(testData.head())\n",
        "print(testData.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3SX5i0HvKlC",
        "outputId": "e4c7061c-8ea1-4ed5-c8d4-aef86adaef5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   id     label  \\\n",
            "0  264183816548130816  positive   \n",
            "1  263405084770172928  negative   \n",
            "2  262163168678248449  negative   \n",
            "3  264249301910310912  negative   \n",
            "4  262682041215234048   neutral   \n",
            "\n",
            "                                               tweet  \n",
            "0  Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
            "1  Theo Walcott is still shit\\u002c watch Rafa an...  \n",
            "2  its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
            "3  Iranian general says Israel\\u2019s Iron Dome c...  \n",
            "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...  \n",
            "neutral     5325\n",
            "positive    4215\n",
            "negative    1798\n",
            "Name: label, dtype: int64\n",
            "                   id     label  \\\n",
            "0  264238274963451904  positive   \n",
            "1  218775148495515649  positive   \n",
            "2  258965201766998017   neutral   \n",
            "3  262926411352903682  negative   \n",
            "4  171874368908050432   neutral   \n",
            "\n",
            "                                               tweet  \n",
            "0  @jjuueellzz down in the Atlantic city, ventnor...  \n",
            "1  Musical awareness: Great Big Beautiful Tomorro...  \n",
            "2  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...  \n",
            "3  Kapan sih lo ngebuktiin,jan ngomong doang Susa...  \n",
            "4  Excuse the connectivity of this live stream, f...  \n",
            "neutral     1513\n",
            "positive    1475\n",
            "negative     559\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=tweetsDatas\n",
        "# max_length is used for max sequence of input\n",
        "max_length = get_max_length(df)\n",
        "print(max_length)\n",
        "\n",
        "train_X, train_Y = preprocess(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maz3Wd7pvY85",
        "outputId": "ed536ecf-b58e-4421-a754-148c02f74aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALL_models"
      ],
      "metadata": {
        "id": "h4UnyOYKvjdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ByW-tyGuvhUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model_1= Sequential()\n",
        "model_1.add(LSTM(64))\n",
        "model_1.add(Dense(2, activation='softmax'))\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ugV0lpT2wJud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train Models"
      ],
      "metadata": {
        "id": "5DXCJAYvv3if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train...')\n",
        "model.fit(train_X, train_Y,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGFxF_HNvofQ",
        "outputId": "25c723b4-cc63-4ed1-dd76-b2b6771b1ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "355/355 [==============================] - 11s 24ms/step - loss: 0.6536 - accuracy: 0.8016\n",
            "Epoch 2/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.6319 - accuracy: 0.7803\n",
            "Epoch 3/10\n",
            "355/355 [==============================] - 8s 23ms/step - loss: 0.6231 - accuracy: 0.7735\n",
            "Epoch 4/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.6156 - accuracy: 0.7747\n",
            "Epoch 5/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.6120 - accuracy: 0.7835\n",
            "Epoch 6/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.6045 - accuracy: 0.7815\n",
            "Epoch 7/10\n",
            "355/355 [==============================] - 9s 25ms/step - loss: 0.5995 - accuracy: 0.7867\n",
            "Epoch 8/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.5926 - accuracy: 0.7855\n",
            "Epoch 9/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.5877 - accuracy: 0.7931\n",
            "Epoch 10/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.5829 - accuracy: 0.7876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae43bda610>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=testData\n",
        "print(test_df.label.value_counts())\n",
        "max_length = get_max_length(test_df)\n",
        "test_X, test_Y = preprocess(test_df)\n",
        "\n",
        "score, acc = model.evaluate(test_X, test_Y, verbose=2)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lb9dxHcvo0G",
        "outputId": "cb88a329-e015-46ec-d5f7-9e6fba03ff0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral     1513\n",
            "positive    1475\n",
            "negative     559\n",
            "Name: label, dtype: int64\n",
            "111/111 - 2s - loss: 0.5866 - accuracy: 0.7857 - 2s/epoch - 18ms/step\n",
            "Test score: 0.5865960121154785\n",
            "Test accuracy: 0.7857344150543213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train...')\n",
        "model_1.fit(train_X, train_Y,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guxnQHu1S8z4",
        "outputId": "cebcf282-13ff-480a-99d9-d3d8f8de34bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "355/355 [==============================] - 12s 27ms/step - loss: 0.6536 - accuracy: 0.8042\n",
            "Epoch 2/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.6309 - accuracy: 0.7725\n",
            "Epoch 3/10\n",
            "355/355 [==============================] - 9s 25ms/step - loss: 0.6227 - accuracy: 0.7777\n",
            "Epoch 4/10\n",
            "355/355 [==============================] - 9s 25ms/step - loss: 0.6135 - accuracy: 0.7811\n",
            "Epoch 5/10\n",
            "355/355 [==============================] - 9s 24ms/step - loss: 0.6116 - accuracy: 0.7821\n",
            "Epoch 6/10\n",
            "355/355 [==============================] - 9s 25ms/step - loss: 0.6022 - accuracy: 0.7862\n",
            "Epoch 7/10\n",
            "355/355 [==============================] - 9s 25ms/step - loss: 0.5962 - accuracy: 0.7840\n",
            "Epoch 8/10\n",
            "355/355 [==============================] - 8s 24ms/step - loss: 0.5913 - accuracy: 0.7886\n",
            "Epoch 9/10\n",
            "355/355 [==============================] - 9s 24ms/step - loss: 0.5845 - accuracy: 0.7951\n",
            "Epoch 10/10\n",
            "355/355 [==============================] - 9s 24ms/step - loss: 0.5804 - accuracy: 0.7909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae44733fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=testData\n",
        "print(test_df.label.value_counts())\n",
        "max_length = get_max_length(test_df)\n",
        "test_X, test_Y = preprocess(test_df)\n",
        "\n",
        "score, acc = model_1.evaluate(test_X, test_Y, verbose=2)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFqn2cidTEI-",
        "outputId": "3161540c-46e0-4e34-fefc-0638f8327219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral     1513\n",
            "positive    1475\n",
            "negative     559\n",
            "Name: label, dtype: int64\n",
            "111/111 - 2s - loss: 0.5927 - accuracy: 0.7922 - 2s/epoch - 18ms/step\n",
            "Test score: 0.5927045941352844\n",
            "Test accuracy: 0.792218804359436\n"
          ]
        }
      ]
    }
  ]
}